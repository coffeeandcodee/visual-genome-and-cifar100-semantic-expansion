{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4800d499",
   "metadata": {},
   "source": [
    "# GENERATING NEW DESCRIPTIONS USING OLLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdf67f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint has 100 words\n",
      "Missing from checkpoint: 0 words: []\n",
      "\n",
      "Will generate 100 descriptions per word\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PASS 1 | Total: 296,049 descriptions\n",
      "Range: 2902 - 3045 per word\n",
      "============================================================\n",
      "[1/100] bus (2902)... ✓ +112 → 3014\n",
      "[2/100] bear (2903)... \n",
      "\n",
      "============================================================\n",
      "⏹️  STOPPED by user after 1 passes\n",
      "   Total descriptions: 296,161\n",
      "   Checkpoint saved ✓\n"
     ]
    }
   ],
   "source": [
    "# GENERATING MORE DESCRIPTIONS USING OLLAMA\n",
    "# ============================================================================\n",
    "# Priority order:\n",
    "#   1. CIFAR-100 words NOT in checkpoint (missing entirely)\n",
    "#   2. Words with fewest descriptions (need more)\n",
    "#\n",
    "# Generates 100 descriptions per word, then moves to next word.\n",
    "# Saves checkpoint after each word for safety.\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import torchvision\n",
    "\n",
    "CHECKPOINT_FILE = \"ollama_interleaved_checkpoint.json\"\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "TARGET_PER_WORD = 100  # Generate 100 descriptions per run\n",
    "\n",
    "# Load checkpoint\n",
    "with open(CHECKPOINT_FILE, 'r') as f:\n",
    "    checkpoint = json.load(f)\n",
    "\n",
    "# Get all CIFAR-100 words\n",
    "cifar100 = torchvision.datasets.CIFAR100(root='./data', download=True)\n",
    "all_cifar_words = set(cifar100.classes)\n",
    "\n",
    "# Find words missing from checkpoint entirely\n",
    "checkpoint_words = set(checkpoint['descriptions'].keys())\n",
    "missing_words = sorted(all_cifar_words - checkpoint_words)\n",
    "\n",
    "# Get words sorted by description count (fewest first)\n",
    "existing_counts = [(word, len(checkpoint['descriptions'].get(word, []))) \n",
    "                   for word in all_cifar_words if word in checkpoint_words]\n",
    "existing_counts.sort(key=lambda x: x[1])\n",
    "\n",
    "# Build priority queue: missing words first, then by count\n",
    "words_to_process = missing_words + [w for w, c in existing_counts]\n",
    "\n",
    "print(f\"Checkpoint has {len(checkpoint_words)} words\")\n",
    "print(f\"Missing from checkpoint: {len(missing_words)} words: {missing_words}\")\n",
    "print(f\"\\nWill generate {TARGET_PER_WORD} descriptions per word\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def clean_description(desc, word):\n",
    "    \"\"\"Clean and validate a description.\"\"\"\n",
    "    desc = desc.lower().strip()\n",
    "    desc = desc.strip('\"\\'')\n",
    "    desc = re.sub(r'^[\\d\\.\\)\\-\\*]+\\s*', '', desc)  # Remove numbering\n",
    "    desc = re.sub(r'_([a-z]+)_', r'\\1', desc)  # Strip markdown underscores\n",
    "    desc = re.sub(r\"(\\b\\w+)'s\\b\", r'\\1', desc)  # Strip possessives\n",
    "    \n",
    "    # Normalize compound words\n",
    "    compounds = [\n",
    "        ('aquarium fish', 'aquarium_fish'), ('lawn mower', 'lawn_mower'),\n",
    "        ('maple tree', 'maple_tree'), ('oak tree', 'oak_tree'),\n",
    "        ('palm tree', 'palm_tree'), ('pickup truck', 'pickup_truck'),\n",
    "        ('pine tree', 'pine_tree'), ('sweet pepper', 'sweet_pepper'),\n",
    "        ('willow tree', 'willow_tree'),\n",
    "    ]\n",
    "    for space_ver, under_ver in compounds:\n",
    "        desc = desc.replace(space_ver, under_ver)\n",
    "    \n",
    "    # Validate\n",
    "    word_check = word.replace('_', ' ') if '_' in word else word\n",
    "    if word not in desc and word_check not in desc:\n",
    "        return None\n",
    "    if len(desc) < 10 or len(desc) > 200:\n",
    "        return None\n",
    "    return desc\n",
    "\n",
    "# ============================================================================\n",
    "# INFINITE LOOP: Keep generating until manually stopped (Ctrl+C or stop button)\n",
    "# ============================================================================\n",
    "# Each pass adds ~100 descriptions per word, prioritizing words with fewest.\n",
    "# Safe to interrupt - checkpoint is saved after every word!\n",
    "# ============================================================================\n",
    "\n",
    "pass_number = 0\n",
    "\n",
    "try:\n",
    "    while True:  # INFINITE LOOP\n",
    "        pass_number += 1\n",
    "        \n",
    "        # Re-sort words by count each pass (prioritize words with fewest)\n",
    "        word_counts = [(word, len(checkpoint['descriptions'].get(word, []))) \n",
    "                       for word in all_cifar_words]\n",
    "        word_counts.sort(key=lambda x: x[1])  # Fewest first\n",
    "        words_to_process = [w for w, c in word_counts]\n",
    "        \n",
    "        min_count = word_counts[0][1]\n",
    "        max_count = word_counts[-1][1]\n",
    "        total = sum(c for _, c in word_counts)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PASS {pass_number} | Total: {total:,} descriptions\")\n",
    "        print(f\"Range: {min_count} - {max_count} per word\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        for i, word in enumerate(words_to_process):\n",
    "            existing = len(checkpoint['descriptions'].get(word, []))\n",
    "            print(f\"[{i+1}/100] {word} ({existing})...\", end=\" \", flush=True)\n",
    "            \n",
    "            new_descriptions = set()\n",
    "            batch_num = 0\n",
    "            \n",
    "            while len(new_descriptions) < TARGET_PER_WORD and batch_num < 15:\n",
    "                batch_num += 1\n",
    "                \n",
    "                prompt = f\"\"\"Generate 50 unique short image captions that a HUMAN would write to describe a photograph containing \"{word}\".\n",
    "\n",
    "Rules:\n",
    "- 4-6 words each\n",
    "- SIMPLE descriptions\n",
    "- Use the exact word \"{word}\". No plurals, and no possesives. The word needs to appear exactly as {word}. KEEP UNDERSCORE IF PRESENT!\n",
    "- The word needs to appear EXACTLY as mentioned in the description, without alternative (e.g use bed and not bedside)\n",
    "- Write like a human describing what they SEE in a real photograph. Simple HUMAN LIKE Descriptions of PHOTOS! Very important!\n",
    "- Varied contexts, colors, actions, settings\n",
    "- Natural language, not robotic or repetitive\n",
    "- Output ONLY the captions, one per line. No numbers, bullets, or explanations.\n",
    "Very Important you make these descriptions NATURAL SOUNDING. You can use commonly used adjectives and descriptions for {word}, but don't be repetitive.\n",
    "\"\"\"\n",
    "\n",
    "                try:\n",
    "                    response = requests.post(OLLAMA_URL, json={\n",
    "                        \"model\": \"llama3.2\",\n",
    "                        \"prompt\": prompt,\n",
    "                        \"stream\": False\n",
    "                    }, timeout=120)\n",
    "                    \n",
    "                    result = response.json()\n",
    "                    text = result.get('response', '')\n",
    "                    \n",
    "                    for line in text.strip().split('\\n'):\n",
    "                        cleaned = clean_description(line, word)\n",
    "                        if cleaned:\n",
    "                            new_descriptions.add(cleaned)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"Error: {e}\", end=\" \", flush=True)\n",
    "                    break\n",
    "            \n",
    "            # Append to checkpoint\n",
    "            if word not in checkpoint['descriptions']:\n",
    "                checkpoint['descriptions'][word] = []\n",
    "            \n",
    "            new_list = list(new_descriptions)\n",
    "            checkpoint['descriptions'][word].extend(new_list)\n",
    "            \n",
    "            # Save checkpoint after each word\n",
    "            with open(CHECKPOINT_FILE, 'w') as f:\n",
    "                json.dump(checkpoint, f)\n",
    "            \n",
    "            new_total = len(checkpoint['descriptions'][word])\n",
    "            print(f\"✓ +{len(new_list)} → {new_total}\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\n\\n{'='*60}\")\n",
    "    print(f\"⏹️  STOPPED by user after {pass_number} passes\")\n",
    "    total = sum(len(d) for d in checkpoint['descriptions'].values())\n",
    "    print(f\"   Total descriptions: {total:,}\")\n",
    "    print(f\"   Checkpoint saved ✓\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e53e6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 words from checkpoint\n",
      "Max descriptions per word: 3045\n",
      "Repeats needed: 4x\n",
      "\n",
      "✓ Created cifar100_words.txt with 1,184,644 descriptions\n",
      "  File size: 48,865,681 characters\n"
     ]
    }
   ],
   "source": [
    "# CREATING .txt FILE FOR NEW DESCRIPTIONS\n",
    "# ============================================================================\n",
    "import json\n",
    "\n",
    "CHECKPOINT_FILE = \"ollama_interleaved_checkpoint.json\"\n",
    "\n",
    "# Load checkpoint\n",
    "with open(CHECKPOINT_FILE, 'r') as f:\n",
    "    checkpoint = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(checkpoint['descriptions'])} words from checkpoint\")\n",
    "\n",
    "# Calculate repeats needed (based on VG corpus size and rare_threshold=0.00025)\n",
    "min_occurrences = int(33662585 * 0.00025) + 1000  # ~9,400\n",
    "max_descs = max(len(d) for d in checkpoint['descriptions'].values())\n",
    "repeats_needed = (min_occurrences // max_descs) + 1\n",
    "\n",
    "print(f\"Max descriptions per word: {max_descs}\")\n",
    "print(f\"Repeats needed: {repeats_needed}x\")\n",
    "\n",
    "# Build interleaved output (cycle through all words evenly)\n",
    "all_descriptions = []\n",
    "words = sorted(checkpoint['descriptions'].keys())\n",
    "\n",
    "for rep in range(repeats_needed):\n",
    "    for desc_idx in range(max_descs):\n",
    "        for word in words:\n",
    "            descs = checkpoint['descriptions'][word]\n",
    "            if desc_idx < len(descs):\n",
    "                all_descriptions.append(descs[desc_idx])\n",
    "\n",
    "# Save to cifar100_words.txt\n",
    "with open('cifar100_word_descriptions.txt', 'w') as f:\n",
    "    f.write(' . '.join(all_descriptions))\n",
    "\n",
    "print(f\"\\n✓ Created cifar100_words.txt with {len(all_descriptions):,} descriptions\")\n",
    "print(f\"  File size: {len(' . '.join(all_descriptions)):,} characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567aba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network from cifar100_words.txt...\n",
      "============================================================\n",
      "Loaded text: 45529689 characters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized: 8635663 tokens\n",
      "Sample tokens: ['projector', 'sarah', 'chives', \"grass'\", 'hostile', 'disposable', 'skateboards', 'unbroken', 'gas', 'chillin', 'plantings', 'afro', \"i've\", 'windowpanes', 'remedies', 'pacifier', 'paddles', 'woody', 'acorn', 'sizzling']\n",
      "Replaced 13176 rare tokens (threshold=0.00025)\n",
      "Final vocabulary: 630 unique tokens\n",
      "Sample tokens: ['table', 'fence', 'motorcycle', 'sunset', 'proudly', 'sweet', 'mouse', 'describe', 'dolphin', 'together', 'my', 'tank', 'mushroom', 'quickly', 'containing', 'blends', 'as', 'upon', 'skin', 'scattered']\n",
      "Graph: 630 nodes, 41647 edges\n",
      "Top tokens by frequency:\n",
      "   1. '<RARE>' (freq=1594556)\n",
      "   2. '.' (freq=1321383)\n",
      "   3. 'a' (freq=516568)\n",
      "   4. 'the' (freq=281616)\n",
      "   5. 'in' (freq=171944)\n",
      "   6. 'on' (freq=150392)\n",
      "   7. 'of' (freq=148188)\n",
      "   8. 'with' (freq=129416)\n",
      "   9. ',' (freq=75540)\n",
      "  10. 'and' (freq=60388)\n",
      "  11. 'old' (freq=50240)\n",
      "  12. 'to' (freq=45912)\n",
      "  13. 'an' (freq=40856)\n",
      "  14. 'through' (freq=38960)\n",
      "  15. 'up' (freq=34864)\n",
      "\n",
      "============================================================\n",
      "CIFAR-100 COVERAGE CHECK:\n",
      "============================================================\n",
      "  Network nodes: 630\n",
      "  Network edges: 41,647\n",
      "\n",
      "  CIFAR-100 words found: 100/100\n",
      "  CIFAR-100 words missing: 0/100\n",
      "\n",
      "  ✅ ALL 100 CIFAR-100 WORDS ARE IN THE NETWORK!\n"
     ]
    }
   ],
   "source": [
    "# BUILDING TEXT NETWORK FROM ONLY CIFAR 100 DESCRIPTIONS\n",
    "from lab2 import process_text_network\n",
    "import torchvision\n",
    "\n",
    "# Build network from CIFAR-100 descriptions only\n",
    "print(\"Building network from cifar100_words.txt...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cifar100_network = process_text_network(\n",
    "    'cifar100_words.txt',\n",
    "    rare_threshold=0.00025,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Check CIFAR-100 coverage\n",
    "cifar100_dataset = torchvision.datasets.CIFAR100(root='./data', download=True)\n",
    "cifar_words = set(cifar100_dataset.classes)\n",
    "network_vocab = set(cifar100_network['nodes'])\n",
    "\n",
    "cifar_found = cifar_words & network_vocab\n",
    "cifar_missing = sorted(cifar_words - network_vocab)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"CIFAR-100 COVERAGE CHECK:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Network nodes: {len(network_vocab)}\")\n",
    "print(f\"  Network edges: {cifar100_network['graph'].number_of_edges():,}\")\n",
    "print(f\"\\n  CIFAR-100 words found: {len(cifar_found)}/100\")\n",
    "print(f\"  CIFAR-100 words missing: {len(cifar_missing)}/100\")\n",
    "\n",
    "if cifar_missing:\n",
    "    print(f\"\\n  ⚠️  Missing words: {cifar_missing}\")\n",
    "else:\n",
    "    print(f\"\\n  ✅ ALL 100 CIFAR-100 WORDS ARE IN THE NETWORK!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02163bf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cifar100_network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check if the words missing from checkpoint are in the network\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# (They might be in the network if they appear frequently in the generated text anyway)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m network_vocab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mcifar100_network\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnodes\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChecking if missing checkpoint words are in the network...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cifar100_network' is not defined"
     ]
    }
   ],
   "source": [
    "# Check if the words missing from checkpoint are in the network\n",
    "# (They might be in the network if they appear frequently in the generated text anyway)\n",
    "\n",
    "network_vocab = set(cifar100_network['nodes'])\n",
    "\n",
    "print(\"Checking if missing checkpoint words are in the network...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for word in missing_from_checkpoint:\n",
    "    if word in network_vocab:\n",
    "        print(f\"  ✅ '{word}' - IN network\")\n",
    "    else:\n",
    "        print(f\"  ❌ '{word}' - NOT in network\")\n",
    "\n",
    "# Summary\n",
    "in_network = [w for w in missing_from_checkpoint if w in network_vocab]\n",
    "not_in_network = [w for w in missing_from_checkpoint if w not in network_vocab]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Of the {len(missing_from_checkpoint)} words missing from checkpoint:\")\n",
    "print(f\"  - {len(in_network)} ARE in the network (appeared in other descriptions)\")\n",
    "print(f\"  - {len(not_in_network)} are NOT in the network\")\n",
    "\n",
    "if not_in_network:\n",
    "    print(f\"\\n⚠️  Words that NEED descriptions generated: {not_in_network}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631181cc",
   "metadata": {},
   "source": [
    "# Quality checking the descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f308f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST 3 DESCRIPTIONS PER WORD:\n",
      "================================================================================\n",
      "\n",
      "apple (2905 total):\n",
      "  1. a big red juicy apple\n",
      "  2. an old red apple with a few bites taken out\n",
      "  3. apple cobbler with vanilla ice cream\n",
      "\n",
      "aquarium_fish (3008 total):\n",
      "  1. colorful aquarium_fish in tank\n",
      "  2. vibrant aquarium_fish leap out\n",
      "  3. aquarium_fish with fins wave\n",
      "\n",
      "baby (3009 total):\n",
      "  1. happy baby playing with toys\n",
      "  2. baby eyes locked on mine sweet\n",
      "  3. baby first smile captured here\n",
      "\n",
      "bear (2903 total):\n",
      "  1. furry bear sitting on a log\n",
      "  2. serene bear in meadow\n",
      "  3. bear standing on two legs\n",
      "\n",
      "beaver (2978 total):\n",
      "  1. little beaver plays with sticks.\n",
      "  2. busy little beaver at work\n",
      "  3. grey beaver walks along shore.\n",
      "\n",
      "bed (3009 total):\n",
      "  1. bed in a small space\n",
      "  2. mossy stone bed seat\n",
      "  3. soft music playing by the bed\n",
      "\n",
      "bee (2927 total):\n",
      "  1. warm sunlight on a sleeping bee\n",
      "  2. bee on a bright yellow bloom\n",
      "  3. bee collecting water from spiderweb\n",
      "\n",
      "beetle (2989 total):\n",
      "  1. green beetle in forest\n",
      "  2. purple beetle on purple flowers\n",
      "  3. beetle walking on stone\n",
      "\n",
      "bicycle (2996 total):\n",
      "  1. man riding bicycle at sunset slowly\n",
      "  2. colorful roadside bicycle\n",
      "  3. bicycle with a broken chain lying still\n",
      "\n",
      "bottle (2924 total):\n",
      "  1. a bottle of soda in my hand\n",
      "  2. old glass bottle in ocean\n",
      "  3. purified bottle of soda\n",
      "\n",
      "bowl (2954 total):\n",
      "  1. white porcelain bowl\n",
      "  2. a delicate china bowl filled with tea\n",
      "  3. bowl of golden rice\n",
      "\n",
      "boy (2952 total):\n",
      "  1. strong boy holding rope\n",
      "  2. silly boy juggling balls\n",
      "  3. big boy holding hands\n",
      "\n",
      "bridge (2944 total):\n",
      "  1. water lilies on the bridge\n",
      "  2. old railroad tracks on bridge\n",
      "  3. ancient roman bridge architecture\n",
      "\n",
      "bus (2902 total):\n",
      "  1. bright sunshine on a crowded bus\n",
      "  2. a small child waving at a passing bus\n",
      "  3. city traffic congestion around a long line of buses\n",
      "\n",
      "butterfly (2984 total):\n",
      "  1. small white butterfly\n",
      "  2. the butterfly rises\n",
      "  3. lovely butterfly in garden\n",
      "\n",
      "camel (2926 total):\n",
      "  1. desert flowers bloom beside camel\n",
      "  2. camels take shelter from a sudden storm.\n",
      "  3. camel majestic long neck\n",
      "\n",
      "can (2929 total):\n",
      "  1. crumpled up can wrapper in the snow\n",
      "  2. paint can in the middle of art project\n",
      "  3. an old can with a funny sticker on it\n",
      "\n",
      "castle (3014 total):\n",
      "  1. lonely castle in valley\n",
      "  2. castle strength stands firm strong\n",
      "  3. castle windows gaze outward\n",
      "\n",
      "caterpillar (3009 total):\n",
      "  1. yellow caterpillar in garden\n",
      "  2. hungry caterpillar munching leaves fast\n",
      "  3. slow crawling caterpillar on leaf\n",
      "\n",
      "cattle (2975 total):\n",
      "  1. golden light on cattle\n",
      "  2. golden hour on open range with cattle\n",
      "  3. a single cattle in the snow\n",
      "\n",
      "chair (2915 total):\n",
      "  1. tall, modern, ergonomic chair\n",
      "  2. old, wooden rocking chair\n",
      "  3. artistic chair with curves\n",
      "\n",
      "chimpanzee (2922 total):\n",
      "  1. agile and nimble chimpanzee climbing\n",
      "  2. chimpanzee playful grin\n",
      "  3. chimpanzee adventurous spirit\n",
      "\n",
      "clock (2998 total):\n",
      "  1. here are 50 unique short image captions that a human would write to describe a photograph containing \"clock\":\n",
      "  2. old wind-up clock turns hands\n",
      "  3. decorative clock on mantlepiece\n",
      "\n",
      "cloud (2933 total):\n",
      "  1. cloud and mountain friends\n",
      "  2. sunset behind a cloud\n",
      "  3. drifting grey cloud above\n",
      "\n",
      "cockroach (2924 total):\n",
      "  1. tiny cockroach on a plate\n",
      "  2. in the shadows, a cockroach hides\n",
      "  3. brown and dusty, this cockroach\n",
      "\n",
      "couch (2931 total):\n",
      "  1. couch between two large windows\n",
      "  2. soft cushions on my new couch\n",
      "  3. shabby chic couch in bungalow\n",
      "\n",
      "crab (2927 total):\n",
      "  1. crusty shell, small crab home\n",
      "  2. fresh crab in the kitchen\n",
      "  3. crab swimming in ocean blue\n",
      "\n",
      "crocodile (2908 total):\n",
      "  1. wading bird approaches a resting crocodile\n",
      "  2. large green crocodile in the wild\n",
      "  3. golden eyes of a crocodile\n",
      "\n",
      "cup (2928 total):\n",
      "  1. a person sipping from a cup\n",
      "  2. a boy holding a cold cup\n",
      "  3. pink cup with yellow ribbons\n",
      "\n",
      "dinosaur (3000 total):\n",
      "  1. ancient creatures like dinosaur\n",
      "  2. colorful picture of ancient dinosaur\n",
      "  3. a tiny dinosaur toy for kids\n",
      "\n",
      "dolphin (2948 total):\n",
      "  1. turquoise water, dolphin swim\n",
      "  2. dolphin plays with bubbles rising\n",
      "  3. dolphin rests in the warm sand\n",
      "\n",
      "elephant (2987 total):\n",
      "  1. mature elephant in the distance\n",
      "  2. elephant standing by riverbank\n",
      "  3. elephant standing alone still\n",
      "\n",
      "flatfish (2950 total):\n",
      "  1. golden flatfish swim freely\n",
      "  2. brown flatfish on sand\n",
      "  3. brown flatfish hide from predators\n",
      "\n",
      "forest (2989 total):\n",
      "  1. swaying forest branches\n",
      "  2. forest wildflowers bloom\n",
      "  3. forest glade peaceful spot\n",
      "\n",
      "fox (3000 total):\n",
      "  1. here are 50 unique short image captions that a human would write to describe a photograph containing \"fox\":\n",
      "  2. fox soft ears listening intently\n",
      "  3. forest home to a cunning fox\n",
      "\n",
      "girl (3022 total):\n",
      "  1. happy girl with big smile\n",
      "  2. beautiful girl in a field\n",
      "  3. girl holding hands with dog walking\n",
      "\n",
      "hamster (2951 total):\n",
      "  1. gentle hamster in bed\n",
      "  2. happy hamster big smile\n",
      "  3. happy little hamster friend\n",
      "\n",
      "house (3004 total):\n",
      "  1. house with a wooden rocking chair\n",
      "  2. old and weathered wooden house\n",
      "  3. cozy little cabin house in woods\n",
      "\n",
      "kangaroo (2909 total):\n",
      "  1. the big brown eyes of kangaroo\n",
      "  2. kangaroo with long ears perked up\n",
      "  3. kangaroo looks directly at us\n",
      "\n",
      "keyboard (2929 total):\n",
      "  1. keyboard in the morning light\n",
      "  2. keyboard and mouse together\n",
      "  3. rusty keyboard in attic\n",
      "\n",
      "lamp (2929 total):\n",
      "  1. lamp on a dusty shelf\n",
      "  2. lamp casting shadows deep\n",
      "  3. darkness illuminated by lamp\n",
      "\n",
      "lawn_mower (2978 total):\n",
      "  1. a lot of work for that little lawn_mower\n",
      "  2. man cutting tall grass with lawn_mower\n",
      "  3. child smile as riding on a lawn_mower\n",
      "\n",
      "leopard (2946 total):\n",
      "  1. a beautiful leopard coat shines\n",
      "  2. leopard resting in shade\n",
      "  3. leopard playful pounces abound\n",
      "\n",
      "lion (2964 total):\n",
      "  1. regal lion mighty roar\n",
      "  2. lion fierce gaze meets yours\n",
      "  3. majestic lion with regal bearing\n",
      "\n",
      "lizard (3000 total):\n",
      "  1. lizard scaly skin so rough\n",
      "  2. ancient lizard in ancient city\n",
      "  3. lizard skin is very rough\n",
      "\n",
      "lobster (2924 total):\n",
      "  1. freshly cooked lobster roll\n",
      "  2. rocky lobster trap setup\n",
      "  3. lobster in a bucket drink\n",
      "\n",
      "man (2905 total):\n",
      "  1. dark man with strong jawline\n",
      "  2. old man fishing by riverbank\n",
      "  3. grimy man in city alley\n",
      "\n",
      "maple_tree (2912 total):\n",
      "  1. twinkling lights reflect off maple_tree\n",
      "  2. nature beauty in maple_tree silhouette\n",
      "  3. snow-covered maple_tree in landscape\n",
      "\n",
      "motorcycle (2914 total):\n",
      "  1. street scene with many motorcycles\n",
      "  2. motorcycle on a beachside cliff\n",
      "  3. man holding motorcycle keys\n",
      "\n",
      "mountain (2967 total):\n",
      "  1. sun sets behind mountain\n",
      "  2. mountain sunrise over water\n",
      "  3. the long quiet mountain road\n",
      "\n",
      "mouse (2939 total):\n",
      "  1. black mouse on white background\n",
      "  2. mouse sitting on keyboard\n",
      "  3. little mouse peeking out\n",
      "\n",
      "mushroom (3008 total):\n",
      "  1. earthy mushroom with cap down\n",
      "  2. dark brown, mossy mushroom hiding\n",
      "  3. mossy mushroom hidden among leaves\n",
      "\n",
      "oak_tree (2981 total):\n",
      "  1. evening light on oak_tree branches\n",
      "  2. oak_tree with colorful leaves glowing\n",
      "  3. snowflakes gently fall around oak_tree\n",
      "\n",
      "orange (2993 total):\n",
      "  1. steamed oranges and ginger tea\n",
      "  2. a basket full of freshly picked oranges\n",
      "  3. glowing orange candlelight flickers\n",
      "\n",
      "orchid (2962 total):\n",
      "  1. forest floor with orchid\n",
      "  2. bright light shines through orchid\n",
      "  3. tiny red spots on orchid\n",
      "\n",
      "otter (3006 total):\n",
      "  1. otter diving into depths\n",
      "  2. wet otter shakes head\n",
      "  3. otter diving into water\n",
      "\n",
      "palm_tree (2993 total):\n",
      "  1. palm_tree against soft focus sky\n",
      "  2. seaside paradise with palm_trees\n",
      "  3. gently falling palm_tree leaves\n",
      "\n",
      "pear (2932 total):\n",
      "  1. autumn fruit basket with pear\n",
      "  2. natural fiber basket with pear\n",
      "  3. summer fruit stand with pear\n",
      "\n",
      "pickup_truck (2920 total):\n",
      "  1. bright red pickup_truck racing to event\n",
      "  2. farm fields with pickup_truck driving by\n",
      "  3. large black pickup_truck with trailer\n",
      "\n",
      "pine_tree (2991 total):\n",
      "  1. pine_tree weathered bark\n",
      "  2. winter wonderland around pine_tree\n",
      "  3. rustic cabin near pine_tree\n",
      "\n",
      "plain (2958 total):\n",
      "  1. white plain wallpaper\n",
      "  2. a plain white plate sits idle\n",
      "  3. a plain brown envelope sits open\n",
      "\n",
      "plate (2970 total):\n",
      "  1. dirty plate in sink\n",
      "  2. fancy plate with flowers\n",
      "  3. wooden plate with grain\n",
      "\n",
      "poppy (2909 total):\n",
      "  1. gardeners care for poppy\n",
      "  2. dark red poppy stem details\n",
      "  3. single poppy on dry ground\n",
      "\n",
      "porcupine (3001 total):\n",
      "  1. colorful porcupine in sunlight\n",
      "  2. forest floor, a porcupine is found\n",
      "  3. cute porcupine face\n",
      "\n",
      "possum (2932 total):\n",
      "  1. gray possum resting on a branch\n",
      "  2. cute and cuddly possum\n",
      "  3. possum peeking out from behind leaves\n",
      "\n",
      "rabbit (2959 total):\n",
      "  1. little grey rabbit playing hide and seek\n",
      "  2. white rabbit in a basket\n",
      "  3. rabbit little pink nose twitch\n",
      "\n",
      "raccoon (2914 total):\n",
      "  1. bandit raccoon looking around\n",
      "  2. raccoon little paws are so tiny\n",
      "  3. forest floor is raccoon domain\n",
      "\n",
      "ray (2992 total):\n",
      "  1. soft rays soothe my weary eyes\n",
      "  2. the ray of sun warm touch\n",
      "  3. gentle rays soothe my soul\n",
      "\n",
      "road (2990 total):\n",
      "  1. road trip at dawn\n",
      "  2. high speed road on a racing bike\n",
      "  3. old tires line the edge of road\n",
      "\n",
      "rocket (3029 total):\n",
      "  1. bright green rocket on launchpad\n",
      "  2. the large rocket body is covered in colorful flames slowly\n",
      "  3. cool robot in rocket suit\n",
      "\n",
      "rose (2962 total):\n",
      "  1. vintage photographs of roses\n",
      "  2. colorful roses in a flower pot\n",
      "  3. romantic stroll through the garden with a rose\n",
      "\n",
      "sea (2917 total):\n",
      "  1. a sailboat racing across sea\n",
      "  2. seagull calling from sea\n",
      "  3. rough sea in storm\n",
      "\n",
      "seal (2953 total):\n",
      "  1. seals balance on one flippers\n",
      "  2. a seal fur shines like silk\n",
      "  3. sealed skin glistens in sun\n",
      "\n",
      "shark (2952 total):\n",
      "  1. shark piercing gaze misses nothing\n",
      "  2. shark breaching the surface\n",
      "  3. shark fins slice through water\n",
      "\n",
      "shrew (2998 total):\n",
      "  1. little brown shrew back\n",
      "  2. shrew scurrying through underbrush\n",
      "  3. shrew fur fluffed up for warmth\n",
      "\n",
      "skunk (3023 total):\n",
      "  1. big skunk in the distance\n",
      "  2. dark side of a tree hides the skunk\n",
      "  3. morning light shines on the skunk\n",
      "\n",
      "skyscraper (3007 total):\n",
      "  1. rooftop skyscraper gardens\n",
      "  2. old skyscraper with history\n",
      "  3. tall skyscraper at sunset\n",
      "\n",
      "snail (2975 total):\n",
      "  1. brown snail on a blade\n",
      "  2. small brown snail shell grows\n",
      "  3. a small snail world exists\n",
      "\n",
      "snake (3025 total):\n",
      "  1. forest creatures watch the snake\n",
      "  2. snake body undulates slowly\n",
      "  3. snake long, slender body\n",
      "\n",
      "spider (2963 total):\n",
      "  1. darkness falls, spider remains still\n",
      "  2. web of a curious spider\n",
      "  3. the spider body is full of movement\n",
      "\n",
      "squirrel (2990 total):\n",
      "  1. wild grey squirrel in forest\n",
      "  2. little squirrel in autumn\n",
      "  3. squirrel eating acorn on ground\n",
      "\n",
      "streetcar (2951 total):\n",
      "  1. people sitting on the streetcar bench\n",
      "  2. golden streetcar in sunset\n",
      "  3. streetcar passing by buildings\n",
      "\n",
      "sunflower (2997 total):\n",
      "  1. beautiful large sunflower blooms\n",
      "  2. field of tall sunflowers swaying\n",
      "  3. simple sunflower arrangement vase\n",
      "\n",
      "sweet_pepper (2914 total):\n",
      "  1. sweet_pepper and hummus wrap\n",
      "  2. pan-seared sweet_pepper medallions\n",
      "  3. vibrant red sweet_peppers on stem\n",
      "\n",
      "table (2930 total):\n",
      "  1. low-profile glass table in an upscale home\n",
      "  2. glass table on a balcony\n",
      "  3. small wooden table on boat\n",
      "\n",
      "tank (2949 total):\n",
      "  1. abandoned tank with broken tracks\n",
      "  2. desert sunset with tank in foreground\n",
      "  3. desert tank with camouflage paint\n",
      "\n",
      "telephone (2926 total):\n",
      "  1. woman holding an antique telephone\n",
      "  2. telephone lying on a patchwork quilt\n",
      "  3. retro-style telephone in a vintage shop\n",
      "\n",
      "television (2926 total):\n",
      "  1. television in a cluttered space\n",
      "  2. television in a box\n",
      "  3. modern flat-screen television on wall\n",
      "\n",
      "tiger (3012 total):\n",
      "  1. a tiger playful swipe at air\n",
      "  2. rare tiger sighting in asia\n",
      "  3. wild tiger on the prowl\n",
      "\n",
      "tractor (2949 total):\n",
      "  1. tractor driving through a muddy pond\n",
      "  2. blue tractor with a big cloud behind it\n",
      "  3. tractor front end is very dusty\n",
      "\n",
      "train (3045 total):\n",
      "  1. long train of carriages together\n",
      "  2. steam train chugs along\n",
      "  3. old train worn seat cracks\n",
      "\n",
      "trout (2910 total):\n",
      "  1. trout on the plate waiting\n",
      "  2. trout caught by surprise\n",
      "  3. elegant trout posing proudly\n",
      "\n",
      "tulip (3008 total):\n",
      "  1. tulip cup open to receive pollen\n",
      "  2. daffodils and tulips in vase\n",
      "  3. tulip flowers in a garden bed\n",
      "\n",
      "turtle (2943 total):\n",
      "  1. rare white turtle on beach walks\n",
      "  2. cute turtle eating treats\n",
      "  3. grey turtle on the ground\n",
      "\n",
      "wardrobe (2910 total):\n",
      "  1. simple, white wooden wardrobe design\n",
      "  2. wardrobe in a dimly lit, mysterious room\n",
      "  3. tattered fabric of an old wardrobe\n",
      "\n",
      "whale (2904 total):\n",
      "  1. close-up of a whale ear\n",
      "  2. whale massive body undulates\n",
      "  3. large whale breaching and splashing\n",
      "\n",
      "willow_tree (2981 total):\n",
      "  1. summer days are warm and languid under a willow_tree shade.\n",
      "  2. winding path beneath willow_tree\n",
      "  3. weathered willow_tree branches stretched out\n",
      "\n",
      "wolf (2945 total):\n",
      "  1. wolf eyes seem wise ancient\n",
      "  2. a lone wolf quiet walk\n",
      "  3. here are 50 unique short image captions that a human would write to describe a photograph containing the word \"wolf\":\n",
      "\n",
      "woman (3000 total):\n",
      "  1. woman tends to her garden\n",
      "  2. lonely woman stares into water\n",
      "  3. smart woman working at desk\n",
      "\n",
      "worm (2954 total):\n",
      "  1. a worm setae poking out\n",
      "  2. wriggling worm in grass\n",
      "  3. tiny worm under bark and leaves\n"
     ]
    }
   ],
   "source": [
    "# Show the LAST 3 descriptions generated for each CIFAR-100 word\n",
    "import json\n",
    "import torchvision\n",
    "\n",
    "CHECKPOINT_FILE = \"ollama_interleaved_checkpoint.json\"\n",
    "\n",
    "with open(CHECKPOINT_FILE, 'r') as f:\n",
    "    checkpoint = json.load(f)\n",
    "\n",
    "# Get CIFAR-100 words\n",
    "cifar100 = torchvision.datasets.CIFAR100(root='./data', download=True)\n",
    "cifar_words = sorted(cifar100.classes)\n",
    "\n",
    "print(\"LAST 3 DESCRIPTIONS PER WORD:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for word in cifar_words:\n",
    "    descs = checkpoint['descriptions'].get(word, [])\n",
    "    count = len(descs)\n",
    "    last_3 = descs[-3:] if count >= 3 else descs\n",
    "    \n",
    "    print(f\"\\n{word} ({count} total):\")\n",
    "    for i, desc in enumerate(last_3, 1):\n",
    "        print(f\"  {i}. {desc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071590f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE CLEAN UP THE DESCRIPTIONS AGAIN HERE. IM SEEING SHIT LIKE \"**worm**\"\" and \"worm-eye\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
