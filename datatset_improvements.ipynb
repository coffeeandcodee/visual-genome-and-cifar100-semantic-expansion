{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9aab088",
   "metadata": {},
   "source": [
    "# Improvements that can be made to SkipGramDataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afce0fa",
   "metadata": {},
   "source": [
    "### Worth adding some of these to the writeup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c461e42",
   "metadata": {},
   "source": [
    "## 1. The SkipGramDataset implementation shown in class **samples negatives uniformly across the vocabulary**.\n",
    "\n",
    "The original Word2Vec paper found that frequency-weighted negative sampling works much better:\n",
    "\n",
    "\n",
    "$$P(w_i) = \\frac{f(w_i)^{0.75}}{\\sum_j f(w_j)^{0.75}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9180a4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "339098c0",
   "metadata": {},
   "source": [
    "The 0.75 exponent is key - it:\n",
    "\n",
    "- Downweights very frequent words (like \"the\", \"a\") so they don't dominate\n",
    "- Upweights rare words slightly so they appear as negatives more often\n",
    "- Creates a smoother distribution than raw frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fbda93",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a41d4b9",
   "metadata": {},
   "source": [
    "## 2. Subsampling Frequent words\n",
    "\n",
    "Subsampling Frequent Words — Quality AND Speed\n",
    "Why it improves quality:\n",
    "Words like \"the\", \"a\", \"is\" co-occur with everything. They're in almost every sentence:\n",
    "\n",
    "\"the dolphin swims\"\n",
    "\"the tiger runs\"\n",
    "\"the table is brown\"\n",
    "\"the car is fast\"\n",
    "\n",
    "So you end up with training pairs like:\n",
    "\n",
    "(the, dolphin)\n",
    "(the, tiger)\n",
    "(the, table)\n",
    "(the, car)\n",
    "\n",
    "The beautiful part:\n",
    "You're not losing information. The 7,000 remaining \"the\" pairs are enough — you didn't need 500,000 examples to learn that \"the\" is a generic article. But you do need every \"dolphin\" and \"whale\" pair because they're rare and semantically meaningful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6799ac",
   "metadata": {},
   "source": [
    "Worth noting the following words did not appear at all in vg_text\n",
    "\n",
    "flatfish             \n",
    "possum               \n",
    "shrew                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8e5cd2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
